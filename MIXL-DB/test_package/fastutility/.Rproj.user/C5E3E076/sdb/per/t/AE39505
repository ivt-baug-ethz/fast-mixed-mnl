{
    "collab_server" : "",
    "contents" : "\n# clean environment\n\nrm(list = ls())\n\n# ------------------------------------------------------------------------------------------------------------#\n#\n# ------- GLOBAL SETTINGS -------\n#\n# ------------------------------------------------------------------------------------------------------------#\n\n# source code\n\nsource(\"source_code.R\") # estimation/postestimation\nsource(\"texout.R\")      # creates formatted latex output\n                        # Note: Use \"multitable.R\" to combine different model outputs\n\n# overall settings\n\nalternatives = 3        # number of alternatives (see predictions output)\nstartingkit = 0         # set to 1 if using betas from a previous run (if available)\npaneldata = 1           # set to 0 for cross-sectional estimation\nmixing = 1              # set to 1 for models that include random parameters\n                        # define number of draws:\n\n                        if (mixing==1) {\n                        Ndraws <- 5\n                        } else Ndraws <- NA\n\nfunctionality = 1       # set to 1 for estimation, 2 for prediction and 3 for uncond./cond. draws\nparallelcomputing = 0   # set to 1 to use multiple cores for estimation\n                        # set number of cores for parallel computing:\n\n                        if (parallelcomputing==1) {\n                             kernel = 4\n                             cl <- makeCluster(kernel)\n                             registerDoParallel(cl)\n                        } else kernel <- 1\n\n# set modelname\n\nmodelname=paste0(\"mixl_train\")\n\n# what time is it?\n\nstart <- Sys.time()\nstart\n\n# set seed: PI and it's first decimals, always a good choice ;)\n\nset.seed(31415926)\n\n\n# ------------------------------------------------------------------------------------------------------------#\n#\n# ------- LOAD DATA AND GET STARTED -------\n#\n# ------------------------------------------------------------------------------------------------------------#\n\n# load and read test data frame and turn it into data table\n\ndatafilename=\"db_data_olymp_300.csv\"\ndata <- read.csv(file = datafilename, stringsAsFactors=F, quote = \"\\\\\\\"\", sep=\";\", row.names=NULL, na = \".\")\ndata=data.table(data)\n\n# subsetting:\n#data <- data[data$jahr == 2015,]\n#data <- data[data$regelung_count < 100,]\n\n# rename person ID and choice\n\n#data=plyr::rename(data, c('choice_id' = 'ID'))\ndata=plyr::rename(data, c('super_id' = 'ID'))\ndata=plyr::rename(data, c('choice_s' = 'CHOICE'))\n\n# number of individuals and choice sets in the data\n\nN=length(unique(data$ID))\nN\nchoicetasks=nrow(data)\nchoicetasks\n\n# check for NAs\n\ncolSums(is.na(data))\n\n# create a running index of choice tasks for each person\n\ndata <- arrange(data, ID)\ndata=data.table(data)\n\nif (paneldata==1) {\ndata[,running_task := regelung_task]\n} else {\ndata[,running_task :=cross_id]\ndata[,ID :=cross_id]\n}\n\n\n# ------------------------------------------------------------------------------------------------------------#\n#\n# ------- SUMMARY STATISTICS AND DATA PROCESSING -------\n#\n# ------------------------------------------------------------------------------------------------------------#\n\nnames(data)\n\ndata[ , U2 :=  rep(1,length(data$ID)) ]\n\nhist(data$CHOICE)\n\nhist(data$train_g)\n\n# ------------------------------------------------------------------------------------------------------------#\n#\n# ------- DEFINE MODELPARAMETERS -------\n#\n# ------------------------------------------------------------------------------------------------------------#\n\nhead(data)\n\nparnames =c('ASC_A',\n            'ASC_U',\n\n            'B_NAH_VERK_A',\n            'B_NAH_VERK_U',\n\n            'B_FERN_VERK_A',\n            'B_FERN_VERK_U',\n\n            'B_BAU_VERK_A',\n            'B_BAU_VERK_U',\n\n            'S11',\n            'S22'\n\n)\n\n# set starting values\n\nstartvalues=c(rep(0,length(parnames)))\n\n# consistency check (should be zero): nil should be zero\n\nnil <- length(parnames)-length(startvalues)\nnil\n\nif (nil != 0) {\n  print(\"You have a serious problem!\")\n  stop()\n}\n\n# convert the above into a beta vector with names\n\nbeta=startvalues\nnames(beta)=parnames\n\n# set fixed parameters\n\nfixedparams=c()\n\n# use new starting values (if available)\n\nif (startingkit==1) {\n\n  # load beta vector\n\n  load(paste0(modelname, \"_est.Rdata\"))\n\n  beta <- est\n\n}\n\n\n# ------------------------------------------------------------------------------------------------------------#\n#\n# ------- RANDOM DRAWS -------\n#\n# ------------------------------------------------------------------------------------------------------------#\n\nif (mixing==1) {\n\n# define dimensions of integral\n\ndimensions=2\n\n# use MLHS draws (proposed by Hess et al., 2006)\n\n#draws=as.matrix(qnorm(mlhs(Ndraws,dimensions,N)))\ndraws=as.matrix(qnorm(halton(Ndraws*N,dimensions)))\n#draws=matrix(runif(N*Ndraws*dimensions),nrow=N*Ndraws,byrow=T)\n\n} # %mixing%\n\n# ------------------------------------------------------------------------------------------------------------#\n#\n# ------- OTHER SPECIFICATIONS AND DATA SPLIT FOR PARALLEL COMPUTING -------\n#\n# ------------------------------------------------------------------------------------------------------------#\n\n# parallelization: create a data list, containing the data frames by parallel-id's as entries\n# split data into number of cores, by ID\n\n  rows.per.cluster <- round_any(N, kernel, f=ceiling)\n  partitions <- unlist(lapply(1:kernel, function(i) {rep(i, rows.per.cluster/kernel)}))\n  data$parallel_id <- partitions[data$ID]\n  data[, p_row_id := ID - min(ID), by = parallel_id]\n\n\n  df.split <- split(data, data$parallel_id)\n\n\nif (kernel > 1) {\n\n  clusterExport(cl, \"Ndraws\")\n  clusterExport(cl, \"draws\")\n\n  clusterApply (cl, df.split, function(x) { data1<<- x })\n\n  clusterApply (cl, 1:kernel, function(x) {\n    k <<- x;\n    N <<- max(data1$p_row_id)+1;  #tell each cluster how big p should be\n    p <<- matrix(0, nrow=N, ncol=Ndraws);\n  })\n\n} else {\n  data1 <- data\n}\n\n\n# ------------------------------------------------------------------------------------------------------------#\n#\n# ------- MODEL SPECIFICATION -------\n#\n# ------- Now moved to c++ file. please edit the utility function there\n#\n# ------------------------------------------------------------------------------------------------------------#\n\n\n\n  #preload data and draws onto each core in the cluster\n  #NB: the memory allocated for each core can be reduced by removing unused columns from the data\n\n\n#  clusterExport(cl, \"df.split\")\n#  clusterExport(cl, \"draws.split\")\n\n\n\n  #backups incase we run on the local session\n  p = matrix(0, nrow=N, ncol=Ndraws)\n\n\nloglike=function(beta) {\n\n  LL <-  foreach(i = 1:kernel, .packages = c('data.table', 'fastutility'),  .combine='c' ) %dopar% {\n\n          individualLoglikelihood(data1, N, beta, draws, Ndraws, p)\n    }\n    return(LL)\n}\n\nseq_r <- loglike(beta)\n\n  microbenchmark(loglike(beta))\n\n\n# ------------------------------------------------------------------------------------------------------------#\n#\n# ------- MODEL ESTIMATION AND OUTPUT -------\n#\n# ------------------------------------------------------------------------------------------------------------#\n\nfunctionality=1\n\n# model estimation\n\nrunmodel()\n\n#rerun with final beta, but with individual likelihoods\n\n\n# calculate runtime\n\nruntime <- Sys.time() - start\n\n#make sure we stop the cluster at the end\nstopCluster(cl)\n\n# formatted output\n\nmodeloutput(model)\n\nrunlabel <- paste0(modelname,\"_\", format(Sys.time(), \"%Y%m%d_%H%M%S_\"))\n\n# create txt-output\n\nout <- capture.output(runtime, modeloutput(model))\ncat(out,file=paste0(runlabel, \"model.txt\"),sep=\"\\n\",append=TRUE)\n\n# create latex-output (see also texout source code)\n\ntexout(model)\nsave(est, file = paste0(modelname, \"_est.Rdata\"))\nsave(robvarcov, file = paste0(modelname, \"_robvarcov.Rdata\"))\n\n",
    "created" : 1507033104497.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "2450043406",
    "id" : "AE39505",
    "lastKnownWriteTime" : 1506453401,
    "last_content_update" : 1506453401,
    "path" : "P:/_TEMP/Molloy/2_MIXL_TRAIN/run_mixl/mixl_train.R",
    "project_path" : null,
    "properties" : {
    },
    "relative_order" : 6,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_source"
}