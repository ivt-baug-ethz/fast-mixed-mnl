{
    "collab_server" : "",
    "contents" : "\n# ------------------------------------------------------------------------------------------------------------#\n#\n# ------- OTHER SPECIFICATIONS AND DATA SPLIT FOR PARALLEL COMPUTING -------\n#\n# ------------------------------------------------------------------------------------------------------------#\n\n#env <<- new.env()\n\n#' @export\nallocatePartition <- function(partition) {\n  env <<- new.env(parent=.GlobalEnv)\n  env$data <-  partition$data # make sure these are really saved\n  env$draws <- partition$draws\n  env$Nindv  <- max(env$data$row_id)+1 #tell each cluster how big p should be\n  env$Ndraws <- Ndraws\n  env$p  <- matrix(0, nrow=env$Nindv, ncol=env$Ndraws) #pre allocate temp matrix for log likelihood calculations\n}\n\n#' @export\nsetUpCluster <- function(kernel, data, Nindv, draws, Ndraws) {\n  #clusterEnv <- createClusterEnvironment()\n  ####split up data for cores\n  rows.per.cluster <- plyr::round_any(Nindv, kernel, f=ceiling) #max number of rows per cluster\n  partitions <- unlist(lapply(1:kernel, function(i) {rep(i, rows.per.cluster/kernel)})) #assign Id's to cores\n  data[, parallel_id := partitions[data$ID]]\n  data[, row_id := ID - min(ID), by = parallel_id] #calculate row_id on each split dataset\n\n  df.split <- split(data, data$parallel_id)\n\n  if (kernel > 1) { #if parallel\n    #create cluster\n    env$cl <- parallel::makeCluster(kernel)\n    doParallel::registerDoParallel(env$cl)\n    parallel::clusterEvalQ(env$cl, library(fastutility))\n\n    #split the draws between cores\n    num_records.list <- lapply(1:kernel, function(k) { max(df.split[[k]]$row_id)+1} ) #get number of ID's allocated to each core\n    draws.cumsum.list <- c(0, cumsum(num_records.list))*Ndraws #calculate where to split the draws matrix\n    draws.split <- lapply(1:(Ndraws-1), function(i) {draws[(draws.cumsum.list[i]+1):draws.cumsum.list[i+1],]})\n\n    #group data and draws by core number\n    par_partitions = purrr::transpose(list(data=df.split, draws = draws.split))\n\n    #parallel::clusterExport(env$cl, \"Ndraws\", envir = )\n\n    #allocate partitions to each core\n    parallel::clusterApply (env$cl, par_partitions, allocatePartition)\n\n\n  } else { #for single core processing\n\n    env$data.cluster <- data\n    env$draws.cluster <- draws\n    env$Nindv  <- Nindv\n    env$Ndraws <- Ndraws\n    env$p  <- matrix(0, nrow=env$Nindv, ncol=env$Ndraws)\n  }\n}\n\n",
    "created" : 1506515828590.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "4099063752",
    "id" : "24736A1E",
    "lastKnownWriteTime" : 1507020072,
    "last_content_update" : 1507020072100,
    "path" : "P:/_TEMP/Molloy/2_MIXL_TRAIN/test_package/fastutility/R/setUpClusterFunction.R",
    "project_path" : "R/setUpClusterFunction.R",
    "properties" : {
        "tempName" : "Untitled4"
    },
    "relative_order" : 3,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_source"
}